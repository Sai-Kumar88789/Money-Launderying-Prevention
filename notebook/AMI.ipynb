{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7588fd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sheela Sai kumar\\anaconda3\\envs\\financePro\\lib\\site-packages\\xgboost\\compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report,ConfusionMatrixDisplay, \\\n",
    "                        precision_score,recall_score,f1_score,roc_auc_score,roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier , AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.combine import SMOTETomek\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779f5d04",
   "metadata": {},
   "source": [
    "#### Nodes and edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8439032b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_classes = pd.read_csv('../elliptic_bitcoin_dataset/elliptic_txs_classes.csv')\n",
    "df_classes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173c425e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3499f8ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df009a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classes['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b230d0c",
   "metadata": {},
   "source": [
    "\n",
    "The graph is made of 203,769 nodes and 234,355 edges. Two percent (4,545) of the nodes are labelled class1 (illicit). Twenty-one percent (42,019) are labelled class2 (licit). The remaining transactions are not labelled with regard to licit versus illicit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47e67fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_edgelist = pd.read_csv('../elliptic_bitcoin_dataset/elliptic_txs_edgelist.csv')\n",
    "df_edgelist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450ae34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edgelist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214e41c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edgelist.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5949acb2",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5cef85",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_features = pd.read_csv('../elliptic_bitcoin_dataset/elliptic_txs_features.csv',header = None )\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe45940",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd032dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b838ebae",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e1f7e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_feat_missing = df_features.isna().sum().reset_index().rename(columns = {0:'no.of missing values'})\n",
    "df_feat_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde2824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_missing[df_feat_missing['no.of missing values']!=0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473511a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_features[1].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33c7275",
   "metadata": {},
   "source": [
    "There are 166 features associated with each node. Due to intellectual property issues, we cannot provide an exact description of all the features in the dataset. There is a time step associated to each node, representing a measure of the time when a transaction was broadcasted to the Bitcoin network. The time steps, running from 1 to 49, are evenly spaced with an interval of about two weeks. Each time step contains a single connected component of transactions that appeared on the blockchain within less than three hours between each other; there are no edges connecting the different time steps.\n",
    "\n",
    "The first 94 features represent local information about the transaction â€“ including the time step described above, number of inputs/outputs, transaction fee, output volume and aggregated figures such as average BTC received (spent) by the inputs/outputs and average number of incoming (outgoing) transactions associated with the inputs/outputs. The remaining 72 features are aggregated features, obtained using transaction information one-hop backward/forward from the center node - giving the maximum, minimum, standard deviation and correlation coefficients of the neighbour transactions for the same information data (number of inputs/outputs, transaction fee, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad0de8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on the given data\n",
    "col = ['txid','timestamp'] + [\"trans_feat_{0}\".format(i) for i in range(1,94)] + ['aggre_feat_{}'.format(j) for j in range(1,73)]\n",
    "print('sample:',col[:5])\n",
    "print('No.of columns :', len(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c0fbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.columns = col\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca6db11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_features['timestamp'].value_counts().sort_index().plot()\n",
    "plt.title('No.of transactions in different time stamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6fc813",
   "metadata": {},
   "source": [
    "Let's split the transaction based on the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f53b82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_merge = pd.merge(df_features,df_classes, left_on = 'txid', right_on = 'txId', how = 'left')\n",
    "df_merge = df_merge.drop(['txId'],axis = 1)\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea4a48c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_group = df_merge.groupby(['timestamp','class'])['txid'].count().reset_index().rename(columns = {'txid':'count'})\n",
    "df_group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37ca333",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,6))\n",
    "sns.lineplot(data = df_group , x = 'timestamp',y ='count',hue = 'class')\n",
    "plt.title('No.of transactions in different time stamp by class')\n",
    "plt.legend(loc = (1,0.85))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4a2fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_missing = df_merge.isna().sum().reset_index().rename(columns = {0:'no.of missing values'})\n",
    "df_merge_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7a82fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_missing[df_merge_missing['no.of missing values']!=0].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75295d9",
   "metadata": {},
   "source": [
    "There are no missing values present in the merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547fe3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ilicit_ids = df_merge.loc[(df_merge['timestamp'] == 20) & (df_merge['class'] == '1'), 'txid']\n",
    "ilicit_edges = df_edgelist.loc[df_edgelist['txId1'].isin(ilicit_ids)]\n",
    "\n",
    "graph = nx.from_pandas_edgelist(ilicit_edges, source = 'txId1', target = 'txId2', )\n",
    "pos = nx.spring_layout(graph)\n",
    "nx.draw_networkx(graph, with_labels=True,pos=pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97299f4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_merge['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6be840",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge['class'].value_counts().plot(kind = 'bar', title = 'class feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87e7d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,cal in enumerate(df_merge['class'].unique()):\n",
    "    print(cal, 'percentage :%.2f' %(df_merge['class'].value_counts()[cal]/df_merge.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3722c5",
   "metadata": {},
   "source": [
    "Here , we can observe that 77% of the data is labled and the other 23% of the data is labelled class1 (illicit) and labelled class2 (illicit).So, first we need to perform with labled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddb34d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_save_labled = df_merge[df_merge['class']!=\"unknown\"]\n",
    "df_save_labled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cb660c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_save_labled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8e39be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_save_labled.to_csv(\"labled_data.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388f4353",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Converting the categorical feature into numerical feature\n",
    "df_merge['class'] = df_merge['class'].replace({'unknown':2,'2':0,'1':1})\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3ad537",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#labled data\n",
    "df_labled = df_merge[df_merge['class']!=2]\n",
    "df_labled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621da534",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4079159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labled['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbf54e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labled['class'].value_counts().plot(kind = 'bar',title = 'labled imbalance data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392366fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labled['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeec200",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_labled.drop(['txid','class'],axis =1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cb48fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_labled['class']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a286974",
   "metadata": {},
   "source": [
    "#### Create Functions for model training evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea017a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clf(y_true,y_predicted):\n",
    "    '''\n",
    "    This function takes y_true and y_predicted values \n",
    "    Return: Accuracy,F1-score, Precision, Recall,Roc-auc score\n",
    "    '''\n",
    "    acc = accuracy_score(y_true,y_predicted) # calculate accuracy\n",
    "    f1 = f1_score(y_true,y_predicted) # calculate f1-score\n",
    "    precision = precision_score(y_true,y_predicted)  # calculate precision\n",
    "    recall = recall_score(y_true,y_predicted) # calculate recall\n",
    "    roc_auc = roc_auc_score(y_true,y_predicted) # calculate roc and auc score\n",
    "    return acc,f1,precision,recall,roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf58ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_cost(y_true,y_predicted):\n",
    "    '''\n",
    "    This function takes y_true , y_predicted\n",
    "    Returns: total cost due to missclassification\n",
    "    '''\n",
    "    tn,fp,fn,tp = confusion_matrix(y_true,y_predicted).ravel()\n",
    "    cost = 10*fp + 500*fn\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1645744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X,y, models):\n",
    "    '''\n",
    "    This function takes in X , and models dictionary as input\n",
    "    It splits the data into Train Test Split\n",
    "    Iterates through the given model dictionary and evaluates the metrics\n",
    "    Returns: DataFrame which contains report of all models with cose\n",
    "    '''\n",
    "    # split the data into train and test\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state = 42)\n",
    "    \n",
    "    cost_list = []\n",
    "    models_list = []\n",
    "    accuracy_list = []\n",
    "    \n",
    "    for i in range(len(list(models))):\n",
    "        model = list(models.values())[i]\n",
    "        model.fit(X_train,y_train) # train the model\n",
    "        \n",
    "        # make predictions\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred  = model.predict(X_test)\n",
    "        \n",
    "        # training the set performance \n",
    "        model_train_accuracy, model_train_f1,model_train_precision,\\\n",
    "        model_train_recall, model_train_roauc_score = evaluate_clf(y_train,y_train_pred)\n",
    "        train_cost = total_cost(y_train,y_train_pred)\n",
    "        \n",
    "        # test set performance\n",
    "        model_test_accuracy, model_test_f1,model_test_precision,\\\n",
    "        model_test_recall, model_test_roauc_score =evaluate_clf(y_test,y_test_pred)\n",
    "        test_cost = total_cost(y_test,y_test_pred)\n",
    "        \n",
    "        print(list(models.keys())[i])\n",
    "        models_list.append(list(models.keys())[i])\n",
    "        \n",
    "        print('Model Performance for trainig test')\n",
    "        print('- Accuracy: {:.4f}' .format(model_train_accuracy))\n",
    "        print('- F1 score: {:.4f}' .format(model_train_f1))\n",
    "        print('- Precision: {:.4f}' .format(model_train_precision))\n",
    "        print('- Recall: {:.4f}' .format(model_train_recall))\n",
    "        print('- Roc Auc score: {:.4f}' .format(model_train_roauc_score))\n",
    "        print(f'- COST: {train_cost}.' )\n",
    "        \n",
    "        print('-----------------------------------------')\n",
    "        \n",
    "        print('Model Performance for test test')\n",
    "        print('- Accuracy: {:.4f}' .format(model_test_accuracy))\n",
    "        print('- F1 score: {:.4f}' .format(model_test_f1))\n",
    "        print('- Precision: {:.4f}' .format(model_test_precision))\n",
    "        print('- Recall: {:.4f}' .format(model_test_recall))\n",
    "        print('- Roc Auc score: {:.4f}' .format(model_test_roauc_score))\n",
    "        print(f'- COST: {test_cost}.')\n",
    "        cost_list.append(test_cost)\n",
    "        print('='*35)\n",
    "        print('\\n')\n",
    "    report = pd.DataFrame(list(zip(models_list,cost_list)),columns = ['Model Name', 'Cost']).sort_values(by = ['Cost'])\n",
    "    \n",
    "    return report  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a1c0f4",
   "metadata": {},
   "source": [
    "#### Handling imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fa20b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resampling the minority class.The strategy can be changed as required\n",
    "smt = SMOTETomek(random_state = 42,sampling_strategy = 'minority', n_jobs = -1)\n",
    "# Fit the model to generate the data\n",
    "X_res,y_res = smt.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d333e544",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Intialize Default models in a dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb2a470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary which contains models for ecperiment\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'Logistice Regression': LogisticRegression(),\n",
    "    'K-Neighbors Classifier': KNeighborsClassifier(),\n",
    "    'XGBoosting Classifier': XGBClassifier(),\n",
    "    'CatBoosting Classifier': CatBoostClassifier(verbose = False),\n",
    "    'AdaBoost Classifier': AdaBoostClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70727ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training all models\n",
    "report = evaluate_models(X_res,y_res,models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0033a18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cd637d",
   "metadata": {},
   "source": [
    "Based on the performance report, it appears that the XGBoost classifier has a better performance on the test set data compared to the K-Neighbors classifier, with a higher accuracy, F1 score, precision, recall, and ROC AUC score. \n",
    "But the XGBoost classifier has a much higher cost (25160) compared to the K-Neighbors classifier (11640).\n",
    "However, for our use case, we achieve a minmum False Positive Rate in XGBoost Classifier. \n",
    "So, the final best model is <b>XGBoost Classifier</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d033eeb",
   "metadata": {},
   "source": [
    "### Fitting the Final Model ang get reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863b95d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = XGBClassifier()\n",
    "\n",
    "# Resampling the minority class\n",
    "smt = SMOTETomek(random_state = 42, sampling_strategy = 'minority',n_jobs=1)\n",
    "X_res, y_res = smt.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27471aca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_res.shape,y_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a416f18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X_res,y_res, test_size = 0.2,random_state = 42)\n",
    "\n",
    "final_model = final_model.fit(X_train,y_train)\n",
    "y_pred = final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbd4f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Final XGBoost Classifier Accuracy Score (Train) :', final_model.score(X_train,y_train))\n",
    "print('Final XGBoost Classifier Accuracy Score (Test) :', accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8109dc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                               display_labels= model.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f629ab75",
   "metadata": {},
   "source": [
    "<b>The best Model is XGBoost Classifier with 99.6% accuracy and cost 25160.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df192ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ecd823",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickled_model = pickle.load(open('model.pkl', 'rb'))\n",
    "y_pred = pickled_model.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c224646",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test the model after saving and get the accuracy of : {:.2f}%'.format(accuracy_score(y_pred,y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df17091d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "a444c19fd90389ec7bccbcf444926015e7a5bbdb0788651a49986602e7124a40"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
